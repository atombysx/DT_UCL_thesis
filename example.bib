@article{example-citation,
    abstract = {{We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.}},
    author = {Anne Author},
    doi = {10.xxxx/example.example.0001},
    journal = {Journal of Classic Examples},
    keywords = {stuff},
    month = jan,
    number = {1},
    pages = {e1001745+},
    pmcid = {PMC3886731},
    pmid = {24415924},
    posted-at = {1970-01-01 00:00:01},
    publisher = {Public Library of Science},
    title = {{Example Journal Paper Title}},
    url = {http://dx.doi.org/10.xxx/example.example.0001},
    volume = {1},
    year = {1970}
}


@article{wen_one-shot_2024,
    title = {One-shot entorhinal maps enable flexible navigation in novel environments},
    volume = {635},
    copyright = {2024 The Author(s)},
    issn = {1476-4687},
    url = {https://www.nature.com/articles/s41586-024-08034-3},
    doi = {10.1038/s41586-024-08034-3},
    abstract = {Animals must navigate changing environments to find food, shelter or mates. In mammals, grid cells in the medial entorhinal cortex construct a neural spatial map of the external environment1–5. However, how grid cell firing patterns rapidly adapt to novel or changing environmental features on a timescale relevant to behaviour remains unknown. Here, by recording over 15,000 grid cells in mice navigating virtual environments, we tracked the real-time state of the grid cell network. This allowed us to observe and predict how altering environmental features influenced grid cell firing patterns on a nearly instantaneous timescale. We found evidence that visual landmarks provide inputs to fixed points in the grid cell network. This resulted in stable grid cell firing patterns in novel and altered environments after a single exposure. Fixed visual landmark inputs also influenced the grid cell network such that altering landmarks induced distortions in grid cell firing patterns. Such distortions could be predicted by a computational model with a fixed landmark to grid cell network architecture. Finally, a medial entorhinal cortex-dependent task revealed that although grid cell firing patterns are distorted by landmark changes, behaviour can adapt via a downstream region implementing behavioural timescale synaptic plasticity6. Overall, our findings reveal how the navigational system of the brain constructs spatial maps that balance rapidity and accuracy. Fixed connections between landmarks and grid cells enable the brain to quickly generate stable spatial maps, essential for navigation in novel or changing environments. Conversely, plasticity in regions downstream from grid cells allows the spatial maps of the brain to more accurately mirror the external spatial environment. More generally, these findings raise the possibility of a broader neural principle: by allocating fixed and plastic connectivity across different networks, the brain can solve problems requiring both rapidity and representational accuracy.},
    language = {en},
    number = {8040},
    urldate = {2025-08-18},
    journal = {Nature},
    author = {Wen, John H. and Sorscher, Ben and Aery Jones, Emily A. and Ganguli, Surya and Giocomo, Lisa M.},
    month = nov,
    year = {2024},
    note = {Publisher: Nature Publishing Group},
    keywords = {Computational neuroscience, Neural circuits},
    pages = {943--950},
}
@article{saleem_coherent_2018,
    title = {Coherent encoding of subjective spatial position in visual cortex and hippocampus},
    volume = {562},
    issn = {14764687},
    doi = {10.1038/s41586-018-0516-1},
    abstract = {A major role of vision is to guide navigation, and navigation is strongly driven by vision1–4. Indeed, the brain’s visual and navigational systems are known to interact5,6, and signals related to position in the environment have been suggested to appear as early as in the visual cortex6,7. Here, to establish the nature of these signals, we recorded in the primary visual cortex (V1) and hippocampal area CA1 while mice traversed a corridor in virtual reality. The corridor contained identical visual landmarks in two positions, so that a purely visual neuron would respond similarly at those positions. Most V1 neurons, however, responded solely or more strongly to the landmarks in one position rather than the other. This modulation of visual responses by spatial location was not explained by factors such as running speed. To assess whether the modulation is related to navigational signals and to the animal’s subjective estimate of position, we trained the mice to lick for a water reward upon reaching a reward zone in the corridor. Neuronal populations in both CA1 and V1 encoded the animal’s position along the corridor, and the errors in their representations were correlated. Moreover, both representations reflected the animal’s subjective estimate of position, inferred from the animal’s licks, better than its actual position. When animals licked in a given location—whether correctly or incorrectly—neural populations in both V1 and CA1 placed the animal in the reward zone. We conclude that visual responses in V1 are controlled by navigational signals, which are coherent with those encoded in hippocampus and reflect the animal’s subjective position. The presence of such navigational signals as early as a primary sensory area suggests that they permeate sensory processing in the cortex.},
    number = {7725},
    journal = {Nature},
    author = {Saleem, Aman B. and Diamanti, E. Mika and Fournier, Julien and Harris, Kenneth D. and Carandini, Matteo},
    month = oct,
    year = {2018},
    pmid = {30202092},
    note = {Publisher: Nature Publishing Group},
    pages = {124--127},
}
@article{mika_diamanti_spatial_2021,
    title = {Spatial modulation of visual responses arises in cortex with active navigation},
    volume = {10},
    issn = {2050084X},
    doi = {10.7554/eLife.63705},
    abstract = {During navigation, the visual responses of neurons in mouse primary visual cortex (V1) are modulated by the animal’s spatial position. Here we show that this spatial modulation is similarly present across multiple higher visual areas but negligible in the main thalamic pathway into V1. Similar to hippocampus, spatial modulation in visual cortex strengthens with experience and with active behavior. Active navigation in a familiar environment, therefore, enhances the spatial modulation of visual signals starting in the cortex.},
    journal = {eLife},
    author = {Mika Diamanti, E. and Reddy, Charu Bai and Schröder, Sylvia and Muzzu, Tomaso and Harris, Kenneth D. and Saleem, Aman B. and Carandini, Matteo},
    month = feb,
    year = {2021},
    pmid = {33538692},
    note = {Publisher: eLife Sciences Publications Ltd},
    pages = {1--15},
}
@article{dubanet_retrosplenial_2024,
    title = {Retrosplenial inputs drive visual representations in the medial entorhinal cortex},
    volume = {43},
    issn = {2211-1247},
    url = {https://www.cell.com/cell-reports/abstract/S2211-1247(24)00799-X},
    doi = {10.1016/j.celrep.2024.114470},
    language = {English},
    number = {7},
    urldate = {2025-08-20},
    journal = {Cell Reports},
    author = {Dubanet, Olivier and Higley, Michael J.},
    month = jul,
    year = {2024},
    pmid = {38985682},
    note = {Publisher: Elsevier},
    keywords = {CP: Neuroscience, circuit, electrophysiology, optogenetic},
}
@article{semedo_cortical_2019,
    title = {Cortical {Areas} {Interact} through a {Communication} {Subspace}},
    volume = {102},
    issn = {10974199},
    doi = {10.1016/j.neuron.2019.01.026},
    abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas. Most brain functions require the selective and flexible routing of neuronal activity between cortical areas. Using paired population recordings from multiple visual cortical areas, Semedo et al. find a population-level mechanism that can achieve this routing, termed a communication subspace.},
    number = {1},
    journal = {Neuron},
    author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
    month = apr,
    year = {2019},
    pmid = {30770252},
    note = {Publisher: Cell Press},
    keywords = {area V2, corticocortical, dimensionality reduction, inter-areal communication, macaque, neural population, neural variability, primary visual cortex, vision, visual cortex},
    pages = {249--259.e4},
}
@article{mcnaughton_path_2006,
    title = {Path integration and the neural basis of the 'cognitive map'},
    volume = {7},
    issn = {1471003X},
    doi = {10.1038/nrn1932},
    abstract = {The hippocampal formation can encode relative spatial location, without reference to external cues, by the integration of linear and angular self-motion (path integration). Theoretical studies, in conjunction with recent empirical discoveries, suggest that the medial entorhinal cortex (MEC) might perform some of the essential underlying computations by means of a unique, periodic synaptic matrix that could be self-organized in early development through a simple, symmetry-breaking operation. The scale at which space is represented increases systematically along the dorsoventral axis in both the hippocampus and the MEC, apparently because of systematic variation in the gain of a movement-speed signal. Convergence of spatially periodic input at multiple scales, from so-called grid cells in the entorhinal cortex, might result in non-periodic spatial firing patterns (place fields) in the hippocampus. © 2006 Nature Publishing Group.},
    number = {8},
    journal = {Nature Reviews Neuroscience},
    author = {McNaughton, Bruce L. and Battaglia, Francesco P. and Jensen, Ole and Moser, Edvard I. and Moser, May Britt},
    year = {2006},
    pmid = {16858394},
    pages = {663--678},
}
@article{etienne_path_2004,
    title = {Path integration in mammals},
    volume = {14},
    issn = {10509631},
    doi = {10.1002/hipo.10173},
    abstract = {It is often assumed that navigation implies the use, by animals, of landmarks indicating the location of the goal. However, many animals (including humans) are able to return to the starting point of a journey, or to other goal sites, by relying on self-motion cues only. This process is known as path integration, and it allows an agent to calculate a route without making use of landmarks. We review the current literature on path integration and its interaction with external, location-based cues. Special importance is given to the correlation between observable behavior and the activity pattern of particular neural cell populations that implement the internal representation of space. In mammals, the latter may well be the first high-level cognitive representation to be understood at the neural level. © 2004 Wiley-Liss, Inc.},
    number = {2},
    journal = {Hippocampus},
    author = {Etienne, Ariane S. and Jeffery, Kathryn J.},
    year = {2004},
    pmid = {15098724},
    keywords = {Cognitive map, Hippocampus, Landmarks, Navigation, Path integration, Self-motion cues},
    pages = {180--192},
}
@article{okeefe_geometric_1996,
    title = {Geometric determinants of the place fields of hippocampal neurons},
    volume = {381},
    copyright = {1996 Springer Nature Limited},
    issn = {1476-4687},
    url = {https://www.nature.com/articles/381425a0},
    doi = {10.1038/381425a0},
    abstract = {THE human hippocampus has been implicated in memory1, in particular episodic2,3 or declarative4 memory. In rats, hippocampal lesions cause selective spatial deficits2,5–7, and hippocampal complex spike cells (place cells) exhibit spatially localized firing8,9, suggesting a role in spatial memory2, although broader functions have also been suggested10,11. Here we report the identification of the environmental features controlling the location and shape of the receptive fields (place fields) of the place cells. This was done by recording from the same cell in four rectangular boxes that differed solely in the length of one or both sides. Most of our results are explained by a model in which the place field is formed by the summation of gaussian tuning curves, each oriented perpendicular to a box wall and peaked at a fixed distance from it.},
    language = {en},
    number = {6581},
    urldate = {2025-08-23},
    journal = {Nature},
    author = {O'Keefe, John and Burgess, Neil},
    month = may,
    year = {1996},
    note = {Publisher: Nature Publishing Group},
    keywords = {Humanities and Social Sciences, Science, multidisciplinary},
    pages = {425--428},
}
@article{barry_experience-dependent_2007,
    title = {Experience-dependent rescaling of entorhinal grids},
    volume = {10},
    issn = {10976256},
    doi = {10.1038/nn1905},
    abstract = {The firing pattern of entorhinal 'grid cells' is thought to provide an intrinsic metric for space. We report a strong experience-dependent environmental influence: the spatial scales of the grids (which are aligned and have fixed relative sizes within each animal) vary parametrically with changes to a familiar environment's size and shape. Thus grid scale reflects an interaction between intrinsic, path-integrative calculation of location and learned associations to the external environment. © 2007 Nature Publishing Group.},
    number = {6},
    journal = {Nature Neuroscience},
    author = {Barry, Caswell and Hayman, Robin and Burgess, Neil and Jeffery, Kathryn J.},
    year = {2007},
    pages = {682--684},
}
@article{gener_tactile_2013,
    title = {Tactile modulation of hippocampal place fields},
    volume = {23},
    issn = {1098-1063},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hipo.22198},
    doi = {10.1002/hipo.22198},
    abstract = {Neural correlates of spatial representation can be found in the activity of the hippocampal place cells. These neurons are characterized by firing whenever the animal is located in a particular area of the space, the place field. Place fields are modulated by sensory cues, such as visual, auditory, or olfactory cues, being the influence of visual inputs the most thoroughly studied. Tactile information gathered by the whiskers has a prominent representation in the rat cerebral cortex. However, the influence of whisker-detected tactile cues on place fields remains an open question. Here we studied place fields in an enriched tactile environment where the remaining sensory cues were occluded. First, place cells were recorded before and after blockade of tactile transmission by means of lidocaine applied on the whisker pad. Following tactile deprivation, the majority of place cells decreased their firing rate and their place fields expanded. We next rotated the tactile cues and 90\% of place fields rotated with them. Our results demonstrate that tactile information is integrated into place cells at least in a tactile-enriched arena and when other sensory cues are not available. © 2013 Wiley Periodicals, Inc.},
    language = {en},
    number = {12},
    urldate = {2025-08-23},
    journal = {Hippocampus},
    author = {Gener, Thomas and Perez-Mendez, Lorena and Sanchez-Vives, Maria V.},
    year = {2013},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hipo.22198},
    keywords = {hippocampus, place cells, somatosensory, spatial navigation, spatial processing},
    pages = {1453--1462},
}
@article{zhang_spatial_2015,
    title = {Spatial {Olfactory} {Learning} {Contributes} to {Place} {Field} {Formation} in the {Hippocampus}},
    volume = {25},
    issn = {1047-3211},
    url = {https://doi.org/10.1093/cercor/bht239},
    doi = {10.1093/cercor/bht239},
    abstract = {Spatial encoding in the hippocampus is multifactorial, and it is well established that metric information about space is conferred by place cells that fire when an animal finds itself in a specific environmental location. Visuospatial contexts comprise a key element in the formation of place fields. Nevertheless, hippocampus does not only use visual cues to generate spatial representations. In the absence of visual input, both humans and other vertebrates studied in this context, are capable of generating very effective spatial representations. However, little is known about the relationship between nonvisual sensory modalities and the establishment of place fields. Substantial evidence exists that olfactory information can be used to learn spatial contexts. Here, we report that learning about a distinct odor constellation in an environment, where visual and auditory cues are suppressed, results in stable place fields that rotate when the odor constellations are rotated and remap when the odor constellations are shuffled. These data support that the hippocampus can use nonvisuospatial resources, and specifically can use spatial olfactory information, to generate spatial representations. Despite the less precise nature of olfactory stimuli compared with visual stimuli, these can substitute for visual inputs to enable the acquisition of metric information about space.},
    number = {2},
    urldate = {2025-08-23},
    journal = {Cerebral Cortex},
    author = {Zhang, Sijie and Manahan-Vaughan, Denise},
    month = feb,
    year = {2015},
    pages = {423--432},
}
@article{hardcastle_multiplexed_2017,
    title = {A {Multiplexed}, {Heterogeneous}, and {Adaptive} {Code} for {Navigation} in {Medial} {Entorhinal} {Cortex}},
    volume = {94},
    issn = {0896-6273},
    url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30237-4},
    doi = {10.1016/j.neuron.2017.03.025},
    language = {English},
    number = {2},
    urldate = {2025-08-20},
    journal = {Neuron},
    author = {Hardcastle, Kiah and Maheswaranathan, Niru and Ganguli, Surya and Giocomo, Lisa M.},
    month = apr,
    year = {2017},
    pmid = {28392071},
    note = {Publisher: Elsevier},
    keywords = {Multiplexed-coding, adaptive coding, computational models of spatial coding, encoding mode, entorhinal cortex, spatial navigation, tuning heterogeneity},
    pages = {375--387.e7},
}
@article{sargolini_conjunctive_2006,
    title = {Conjunctive representation of position, direction, and velocity in entorhinal cortex},
    volume = {312},
    issn = {00368075},
    doi = {10.1126/science.1125572},
    abstract = {Grid cells in the medial entorhinal cortex (MEC) are part of an environment-independent spatial coordinate system. To determine how information about location, direction, and distance is integrated in the grid-cell network, we recorded from each principal cell layer of MEC in rats that explored two-dimensional environments. Whereas layer II was predominated by grid cells, grid cells colocalized with head-direction cells and conjunctive grid x head-direction cells in the deeper layers. All cell types were modulated by running speed. The conjunction of positional, directional, and translational information in a single MEC cell type may enable grid coordinates to be updated during self-motion-based navigation.},
    number = {5774},
    journal = {Science},
    author = {Sargolini, Francesca and Fyhn, Marianne and Hafting, Torkel and McNaughton, Bruce L. and Witter, Menno P. and Moser, May Britt and Moser, Edvard I.},
    year = {2006},
    pages = {758--762},
}
@article{chen_absence_2016,
    title = {Absence of {Visual} {Input} {Results} in the {Disruption} of {Grid} {Cell} {Firing} in the {Mouse}},
    volume = {26},
    issn = {0960-9822},
    url = {https://www.cell.com/current-biology/abstract/S0960-9822(16)30683-2},
    doi = {10.1016/j.cub.2016.06.043},
    language = {English},
    number = {17},
    urldate = {2025-08-23},
    journal = {Current Biology},
    author = {Chen, Guifen and Manson, Daniel and Cacucci, Francesca and Wills, Thomas Joseph},
    month = sep,
    year = {2016},
    note = {Publisher: Elsevier},
    pages = {2335--2342},
}
@article{chen_how_2013,
    title = {How vision and movement combine in the hippocampal place code},
    volume = {110},
    issn = {00278424},
    doi = {10.1073/pnas.1215834110},
    abstract = {How do external environmental and internal movement-related information combine to tell us where we are? We examined the neural representation of environmental location provided by hippocampal place cells while mice navigated a virtual reality environment in which both types of information could be manipulated. Extracellular recordings were made from region CA1 of head-fixed mice navigating a virtual linear track and running in a similar real environment. Despite the absence of vestibular motion signals, normal place cell firing and theta rhythmicity were found. Visual information alone was sufficient for localized firing in 25\% of place cells and to maintain a local field potential theta rhythm (but with significantly reduced power). Additional movement-related information was required for normally localized firing by the remaining 75\% of place cells. Trials in which movement and visual information were put into conflict showed that they combined nonlinearly to control firing location, and that the relative influence of movement versus visual information varied widely across place cells. However, within this heterogeneity, the behavior of fully half of the place cells conformed to a model of path integration in which the presence of visual cues at the start of each run together with subsequent movement-related updating of position was sufficient to maintain normal fields.},
    number = {1},
    journal = {Proceedings of the National Academy of Sciences of the United States of America},
    author = {Chen, Guifen and King, John A. and Burgess, Neil and O'Keefe, John},
    month = jan,
    year = {2013},
    pmid = {23256159},
    pages = {378--383},
}
@article{nguyen_medial_2024,
    title = {The medial entorhinal cortex encodes multisensory spatial information},
    volume = {43},
    issn = {2211-1247},
    url = {https://www.cell.com/cell-reports/abstract/S2211-1247(24)01164-1},
    doi = {10.1016/j.celrep.2024.114813},
    language = {English},
    number = {10},
    urldate = {2025-08-23},
    journal = {Cell Reports},
    author = {Nguyen, Duc and Wang, Garret and Wafa, Talah and Fitzgerald, Tracy and Gu, Yi},
    month = oct,
    year = {2024},
    pmid = {39395171},
    note = {Publisher: Elsevier},
    keywords = {CP: Neuroscience, Medial entorhinal cortex, auditory, cognitive map, multisensory, spatial navigation, two-photon imaging, unisensory, virtual reality, visual},
}
@article{campbell_principles_2018,
    title = {Principles governing the integration of landmark and self-motion cues in entorhinal cortical codes for navigation},
    volume = {21},
    copyright = {2018 The Author(s)},
    issn = {1546-1726},
    url = {https://www.nature.com/articles/s41593-018-0189-y},
    doi = {10.1038/s41593-018-0189-y},
    abstract = {To guide navigation, the nervous system integrates multisensory self-motion and landmark information. We dissected how these inputs generate spatial representations by recording entorhinal grid, border and speed cells in mice navigating virtual environments. Manipulating the gain between the animal’s locomotion and the visual scene revealed that border cells responded to landmark cues while grid and speed cells responded to combinations of locomotion, optic flow and landmark cues in a context-dependent manner, with optic flow becoming more influential when it was faster than expected. A network model explained these results by revealing a phase transition between two regimes in which grid cells remain coherent with or break away from the landmark reference frame. Moreover, during path-integration-based navigation, mice estimated their position following principles predicted by our recordings. Together, these results provide a theoretical framework for understanding how landmark and self-motion cues combine during navigation to generate spatial representations and guide behavior.},
    language = {en},
    number = {8},
    urldate = {2025-08-23},
    journal = {Nature Neuroscience},
    author = {Campbell, Malcolm G. and Ocko, Samuel A. and Mallory, Caitlin S. and Low, Isabel I. C. and Ganguli, Surya and Giocomo, Lisa M.},
    month = aug,
    year = {2018},
    note = {Publisher: Nature Publishing Group},
    keywords = {Neural circuits, Neuroscience},
    pages = {1096--1106},
}
@article{rolls_mechanisms_2013,
    title = {The mechanisms for pattern completion and pattern separation in the hippocampus},
    volume = {7},
    issn = {1662-5137},
    url = {https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2013.00074/full},
    doi = {10.3389/fnsys.2013.00074},
    abstract = {The mechanisms for pattern completion and pattern separation are described in the context of a theory of hippocampal function in which the hippocampal CA3 system operates as a single attractor or autoassociation network to enable rapid, one-trial, associations between any spatial location (place in rodents, or spatial view in primates) and an object or reward, and to provide for completion of the whole memory during recall from any part. The factors important in the pattern completion in CA3 together with a large number of independent memories stored in CA3 include a sparse distributed representation which is enhanced by the graded firing rates of CA3 neurons, representations that are independent due to the randomizing effect of the mossy fibers, heterosynaptic long-term depression as well as long-term potentiation in the recurrent collateral synapses, and diluted connectivity to minimize the number of multiple synapses between any pair of CA3 neurons which otherwise distort the basins of attraction. Recall of information from CA3 is implemented by the entorhinal cortex perforant path synapses to CA3 cells, which acting as a pattern associator allow some pattern generalization. Pattern separation is performed in the dentate granule cells using competitive learning to convert grid-like entorhinal cortex firing to place-like fields. Pattern separation in CA3, which is important for completion of any one of the stored patterns from a fragment, is provided for by the randomizing effect of the mossy fiber synapses to which neurogenesis may contribute, by the large number of dentate granule cells each with a sparse representation, and by the sparse independent representations in CA3. Recall to the neocortex is achieved by a reverse hierarchical series of pattern association networks implemented by the hippocampo-cortical backprojections, each one of which performs some pattern generalization, to retrieve a complete pattern of cortical firing in higher-order cortical areas},
    language = {English},
    urldate = {2025-08-23},
    journal = {Frontiers in Systems Neuroscience},
    author = {Rolls, Edmund},
    month = oct,
    year = {2013},
    note = {Publisher: Frontiers},
    keywords = {Hippocampus, Pattern Separation, Recall, attractor network, competitive network, completion, episodic memory, pattern association network},
}
@article{wills_attractor_2005,
    title = {Attractor {Dynamics} in the {Hippocampal} {Representation} of the {Local} {Environment}},
    volume = {308},
    url = {https://www.science.org/doi/abs/10.1126/science.1108905},
    doi = {10.1126/science.1108905},
    abstract = {Memories are thought to be attractor states of neuronal representations, with the hippocampus a likely substrate for context-dependent episodic memories. However, such states have not been directly observed. For example, the hippocampal place cell representation of location was previously found to respond continuously to changes in environmental shape alone. We report that exposure to novel square and circular environments made of different materials creates attractor representations for both shapes: Place cells abruptly and simultaneously switch between representations as environmental shape changes incrementally. This enables study of attractor dynamics in a cognitive representation and may correspond to the formation of distinct contexts in context-dependent memory.},
    number = {5723},
    urldate = {2025-08-23},
    journal = {Science},
    author = {Wills, Tom J. and Lever, Colin and Cacucci, Francesca and Burgess, Neil and O'Keefe, John},
    month = may,
    year = {2005},
    note = {Publisher: American Association for the Advancement of Science},
    pages = {873--876},
}
@article{anderson_heterogeneous_2003,
    title = {Heterogeneous {Modulation} of {Place} {Cell} {Firing} by {Changes} in {Context}},
    volume = {23},
    copyright = {Copyright © 2003 Society for Neuroscience 0270-6474/03/238827-09.00/0},
    issn = {0270-6474, 1529-2401},
    url = {https://www.jneurosci.org/content/23/26/8827},
    doi = {10.1523/JNEUROSCI.23-26-08827.2003},
    abstract = {Hippocampal place cells show spatially localized activity that can be modulated by both geometric information (e.g., the distances and directions of features in the environment) and nongeometric information (e.g., colors, odors, and possibly behaviors). Nongeometric information may allow the discrimination of different spatial contexts. Understanding how nongeometric (or contextual) information affects hippocampal activity is important in light of proposals that the hippocampus may play a role in constructing a representation of spatial context. We investigated the contextual modulation of place cell activity by recording hippocampal place cells while rats foraged in compound contexts comprising black or white color paired with lemon or vanilla odor. Some cells responded to the color or odor changes alone, but most responded to varying combinations of both. Thus, we demonstrate, for the first time, that there is a heterogeneous input by contextual inputs into the hippocampus. We propose a model of contextual remapping of place cells in which the geometric inputs are selectively activated by subsets of contextual stimuli. Because it appears that different place cells are affected by different subsets of contextual stimuli, the representation of the entire context would require activity at the population level, supporting a role for the hippocampus in constructing a representation of spatial context.},
    language = {en},
    number = {26},
    urldate = {2025-08-23},
    journal = {Journal of Neuroscience},
    author = {Anderson, Michael I. and Jeffery, Kathryn J.},
    month = oct,
    year = {2003},
    pmid = {14523083},
    note = {Publisher: Society for Neuroscience
Section: Behavioral/Systems/Cognitive},
    keywords = {context, hippocampus, place cells, remapping, single-unit, spatial representation},
    pages = {8827--8835},
}
@article{fyhn_hippocampal_2007,
    title = {Hippocampal remapping and grid realignment in entorhinal cortex},
    volume = {446},
    copyright = {2006 Springer Nature Limited},
    issn = {1476-4687},
    url = {https://www.nature.com/articles/nature05601},
    doi = {10.1038/nature05601},
    abstract = {The ability to find one's way depends on the brain's ability to integrate information about location, direction and distance. Recent advances have pointed to 'grid cells' in the brain's entorhinal cortex as one component of the mechanism for calculating position, but the neuronal network computations responsible for spatial navigation and spatial memory formation are not understood. Experiments in rats tasked to track down their food in changing environments now reveal two distinct codes for memory representation in the hippocampus. The formation of statistically independent representations in hippocampal place cells ('remapping') is invariably preceded by a coherent migration of the corresponding ensemble maps in the entorhinal cortex. This allows an animal's position to be represented and updated by the same translation mechanism as it encounters different environments.},
    language = {en},
    number = {7132},
    urldate = {2025-08-24},
    journal = {Nature},
    author = {Fyhn, Marianne and Hafting, Torkel and Treves, Alessandro and Moser, May-Britt and Moser, Edvard I.},
    month = mar,
    year = {2007},
    note = {Publisher: Nature Publishing Group},
    keywords = {Humanities and Social Sciences, Science, multidisciplinary},
    pages = {190--194},
}
@article{low_dynamic_2021,
    title = {Dynamic and reversible remapping of network representations in an unchanging environment},
    volume = {109},
    issn = {08966273},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627321005043},
    doi = {10.1016/j.neuron.2021.07.005},
    abstract = {Neurons in the medial entorhinal cortex alter their ﬁring properties in response to environmental changes. This ﬂexibility in neural coding is hypothesized to support navigation and memory by dividing sensory experience into unique episodes. However, it is unknown how the entorhinal circuit as a whole transitions between different representations when sensory information is not delineated into discrete contexts. Here we describe rapid and reversible transitions between multiple spatial maps of an unchanging task and environment. These remapping events were synchronized across hundreds of neurons, differentially affected navigational cell types, and correlated with changes in running speed. Despite widespread changes in spatial coding, remapping comprised a translation along a single dimension in population-level activity space, enabling simple decoding strategies. These ﬁndings provoke reconsideration of how the medial entorhinal cortex dynamically represents space and suggest a remarkable capacity of cortical circuits to rapidly and substantially reorganize their neural representations.},
    language = {en},
    number = {18},
    urldate = {2025-08-24},
    journal = {Neuron},
    author = {Low, Isabel I.C. and Williams, Alex H. and Campbell, Malcolm G. and Linderman, Scott W. and Giocomo, Lisa M.},
    month = sep,
    year = {2021},
    pages = {2967--2980.e11},
}
@article{saleem_integration_2013,
    title = {Integration of visual motion and locomotion in mouse visual cortex},
    volume = {16},
    copyright = {2013 Springer Nature America, Inc.},
    issn = {1546-1726},
    url = {https://www.nature.com/articles/nn.3567},
    doi = {10.1038/nn.3567},
    abstract = {The primary visual cortex (V1) carries signals related to visual speed, and its responses are also affected by run speed. Here the authors report that nearly half of the V1 neurons were reliably driven by combinations of visual speed and run speed. As a population, V1 neurons predicted a linear combination of visual and run speed better than visual or run speeds alone.},
    language = {en},
    number = {12},
    urldate = {2025-08-24},
    journal = {Nature Neuroscience},
    author = {Saleem, Aman B. and Ayaz, Aslı and Jeffery, Kathryn J. and Harris, Kenneth D. and Carandini, Matteo},
    month = dec,
    year = {2013},
    note = {Publisher: Nature Publishing Group},
    keywords = {Navigation, Striate cortex},
    pages = {1864--1869},
}
@article{horrocks_flexible_2024,
    title = {Flexible neural population dynamics govern the speed and stability of sensory encoding in mouse visual cortex},
    volume = {15},
    copyright = {2024 The Author(s)},
    issn = {2041-1723},
    url = {https://www.nature.com/articles/s41467-024-50563-y},
    doi = {10.1038/s41467-024-50563-y},
    abstract = {Time courses of neural responses underlie real-time sensory processing and perception. How these temporal dynamics change may be fundamental to how sensory systems adapt to different perceptual demands. By simultaneously recording from hundreds of neurons in mouse primary visual cortex, we examined neural population responses to visual stimuli at sub-second timescales, during different behavioural states. We discovered that during active behavioural states characterised by locomotion, single-neurons shift from transient to sustained response modes, facilitating rapid emergence of visual stimulus tuning. Differences in single-neuron response dynamics were associated with changes in temporal dynamics of neural correlations, including faster stabilisation of stimulus-evoked changes in the structure of correlations during locomotion. Using Factor Analysis, we examined temporal dynamics of latent population responses and discovered that trajectories of population activity make more direct transitions between baseline and stimulus-encoding neural states during locomotion. This could be partly explained by dampening of oscillatory dynamics present during stationary behavioural states. Functionally, changes in temporal response dynamics collectively enabled faster, more stable and more efficient encoding of new visual information during locomotion. These findings reveal a principle of how sensory systems adapt to perceptual demands, where flexible neural population dynamics govern the speed and stability of sensory encoding.},
    language = {en},
    number = {1},
    urldate = {2025-08-24},
    journal = {Nature Communications},
    author = {Horrocks, Edward A. B. and Rodrigues, Fabio R. and Saleem, Aman B.},
    month = jul,
    year = {2024},
    note = {Publisher: Nature Publishing Group},
    keywords = {Dynamical systems, Neural encoding, Sensory processing, Visual system},
    pages = {6415},
}
@article{muzzu_feature_2021,
    title = {Feature selectivity can explain mismatch signals in mouse visual cortex},
    volume = {37},
    issn = {2211-1247},
    url = {https://www.cell.com/cell-reports/abstract/S2211-1247(21)01226-2},
    doi = {10.1016/j.celrep.2021.109772},
    language = {English},
    number = {1},
    urldate = {2025-08-24},
    journal = {Cell Reports},
    author = {Muzzu, Tomaso and Saleem, Aman B.},
    month = oct,
    year = {2021},
    pmid = {34610298},
    note = {Publisher: Elsevier},
    keywords = {active sensing, locomotion, predictive coding, sensorimotor, visual cortex},
}
@article{zmarz_mismatch_2016,
    title = {Mismatch {Receptive} {Fields} in {Mouse} {Visual} {Cortex}},
    volume = {92},
    issn = {0896-6273},
    url = {https://www.cell.com/neuron/abstract/S0896-6273(16)30699-7},
    doi = {10.1016/j.neuron.2016.09.057},
    language = {English},
    number = {4},
    urldate = {2025-08-24},
    journal = {Neuron},
    author = {Zmarz, Pawel and Keller, Georg B.},
    month = nov,
    year = {2016},
    pmid = {27974161},
    note = {Publisher: Elsevier},
    keywords = {predictive coding, receptive fields, sensorimotor integration, visual cortex},
    pages = {766--772},
}
@article{keller_sensorimotor_2012,
    title = {Sensorimotor {Mismatch} {Signals} in {Primary} {Visual} {Cortex} of the {Behaving} {Mouse}},
    volume = {74},
    issn = {0896-6273},
    url = {https://www.cell.com/neuron/abstract/S0896-6273(12)00384-4},
    doi = {10.1016/j.neuron.2012.03.040},
    language = {English},
    number = {5},
    urldate = {2025-08-24},
    journal = {Neuron},
    author = {Keller, Georg B. and Bonhoeffer, Tobias and Hübener, Mark},
    month = jun,
    year = {2012},
    pmid = {22681686},
    note = {Publisher: Elsevier},
    pages = {809--815},
}
@article{muzzu_redefining_2023,
    title = {Redefining sensorimotor mismatch selectivity in the visual cortex},
    volume = {42},
    issn = {2211-1247},
    url = {https://www.cell.com/cell-reports/abstract/S2211-1247(23)00109-2},
    doi = {10.1016/j.celrep.2023.112098},
    language = {English},
    number = {3},
    urldate = {2025-08-24},
    journal = {Cell Reports},
    author = {Muzzu, Tomaso and Saleem, Aman B.},
    month = mar,
    year = {2023},
    pmid = {36821444},
    note = {Publisher: Elsevier},
    keywords = {CP: Neuroscience, locomotion, mouse vision, predictive coding},
}
@article{ayaz_locomotion_2013,
    title = {Locomotion {Controls} {Spatial} {Integration} in {Mouse} {Visual} {Cortex}},
    volume = {23},
    issn = {0960-9822},
    url = {https://www.cell.com/current-biology/abstract/S0960-9822(13)00420-X},
    doi = {10.1016/j.cub.2013.04.012},
    language = {English},
    number = {10},
    urldate = {2025-08-24},
    journal = {Current Biology},
    author = {Ayaz, Aslı and Saleem, Aman B. and Schölvinck, Marieke L. and Carandini, Matteo},
    month = may,
    year = {2013},
    pmid = {23664971},
    note = {Publisher: Elsevier},
    pages = {890--894},
}
@article{polack_cellular_2013,
    title = {Cellular mechanisms of brain state–dependent gain modulation in visual cortex},
    volume = {16},
    copyright = {2013 Springer Nature America, Inc.},
    issn = {1546-1726},
    url = {https://www.nature.com/articles/nn.3464},
    doi = {10.1038/nn.3464},
    abstract = {What are the mechanisms that control gain in the cortex during distinct behavioral states? In this article, the authors record from cortical excitatory and inhibitory neurons from the visual cortex of mice running on a spherical treadmill and find that cholinergic and noradrenergic modulatory inputs play distinct roles in the dynamics of the membrane potential of these neurons during locomotion and immobility.},
    language = {en},
    number = {9},
    urldate = {2025-08-24},
    journal = {Nature Neuroscience},
    author = {Polack, Pierre-Olivier and Friedman, Jonathan and Golshani, Peyman},
    month = sep,
    year = {2013},
    note = {Publisher: Nature Publishing Group},
    keywords = {Cellular neuroscience, Neuronal physiology, Striate cortex},
    pages = {1331--1339},
}
@article{schroder_arousal_2020,
    title = {Arousal {Modulates} {Retinal} {Output}},
    volume = {107},
    issn = {0896-6273},
    url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30318-4},
    doi = {10.1016/j.neuron.2020.04.026},
    language = {English},
    number = {3},
    urldate = {2025-08-24},
    journal = {Neuron},
    author = {Schröder, Sylvia and Steinmetz, Nicholas A. and Krumin, Michael and Pachitariu, Marius and Rizzi, Matteo and Lagnado, Leon and Harris, Kenneth D. and Carandini, Matteo},
    month = aug,
    year = {2020},
    pmid = {32445624},
    note = {Publisher: Elsevier},
    keywords = {arousal, locomotion, retina, superior colliculus, vision},
    pages = {487--495.e9},
}
@article{stringer_spontaneous_2019,
    title = {Spontaneous behaviors drive multidimensional, brainwide activity},
    volume = {364},
    url = {https://www.science.org/doi/10.1126/science.aav7893},
    doi = {10.1126/science.aav7893},
    abstract = {Neuronal populations in sensory cortex produce variable responses to sensory stimuli and exhibit intricate spontaneous activity even without external sensory input. Cortical variability and spontaneous activity have been variously proposed to represent random noise, recall of prior experience, or encoding of ongoing behavioral and cognitive variables. Recording more than 10,000 neurons in mouse visual cortex, we observed that spontaneous activity reliably encoded a high-dimensional latent state, which was partially related to the mouse’s ongoing behavior and was represented not just in visual cortex but also across the forebrain. Sensory inputs did not interrupt this ongoing signal but added onto it a representation of external stimuli in orthogonal dimensions. Thus, visual cortical population activity, despite its apparently noisy structure, reliably encodes an orthogonal fusion of sensory and multidimensional behavioral information.},
    number = {6437},
    urldate = {2025-08-24},
    journal = {Science},
    author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D.},
    month = apr,
    year = {2019},
    note = {Publisher: American Association for the Advancement of Science},
    pages = {eaav7893},
}
@article{orlandi_distributed_2023,
    title = {Distributed context-dependent choice information in mouse posterior cortex},
    volume = {14},
    copyright = {2023 The Author(s)},
    issn = {2041-1723},
    url = {https://www.nature.com/articles/s41467-023-35824-6},
    doi = {10.1038/s41467-023-35824-6},
    abstract = {Choice information appears in multi-area brain networks mixed with sensory, motor, and cognitive variables. In the posterior cortex—traditionally implicated in decision computations—the presence, strength, and area specificity of choice signals are highly variable, limiting a cohesive understanding of their computational significance. Examining the mesoscale activity in the mouse posterior cortex during a visual task, we found that choice signals defined a decision variable in a low-dimensional embedding space with a prominent contribution along the ventral visual stream. Their subspace was near-orthogonal to concurrently represented sensory and motor-related activations, with modulations by task difficulty and by the animals’ attention state. A recurrent neural network trained with animals’ choices revealed an equivalent decision variable whose context-dependent dynamics agreed with that of the neural data. Our results demonstrated an independent, multi-area decision variable in the posterior cortex, controlled by task features and cognitive demands, possibly linked to contextual inference computations in dynamic animal–environment interactions.},
    language = {en},
    number = {1},
    urldate = {2025-08-24},
    journal = {Nature Communications},
    author = {Orlandi, Javier G. and Abdolrahmani, Mohammad and Aoki, Ryo and Lyamzin, Dmitry R. and Benucci, Andrea},
    month = jan,
    year = {2023},
    note = {Publisher: Nature Publishing Group},
    keywords = {Cognitive neuroscience, Network models, Neural circuits, Visual system},
    pages = {192},
}
@article{steinmetz_distributed_2019,
    title = {Distributed coding of choice, action and engagement across the mouse brain},
    volume = {576},
    url = {https://www.nature.com/articles/s41586-019-1787-x},
    number = {7786},
    urldate = {2025-08-24},
    journal = {Nature},
    author = {Steinmetz, Nicholas A. and Zatka-Haas, Peter and Carandini, Matteo and Harris, Kenneth D.},
    year = {2019},
    note = {Publisher: Nature Publishing Group UK London},
    pages = {266--273},
}
@article{zatka-haas_sensory_2021,
    title = {Sensory coding and the causal impact of mouse cortex in a visual decision},
    volume = {10},
    issn = {2050-084X},
    url = {https://doi.org/10.7554/eLife.63163},
    doi = {10.7554/eLife.63163},
    abstract = {Correlates of sensory stimuli and motor actions are found in multiple cortical areas, but such correlates do not indicate whether these areas are causally relevant to task performance. We trained mice to discriminate visual contrast and report their decision by steering a wheel. Widefield calcium imaging and Neuropixels recordings in cortex revealed stimulus-related activity in visual (VIS) and frontal (MOs) areas, and widespread movement-related activity across the whole dorsal cortex. Optogenetic inactivation biased choices only when targeted at VIS and MOs,proportionally to each site's encoding of the visual stimulus, and at times corresponding to peak stimulus decoding. A neurometric model based on summing and subtracting activity in VIS and MOs successfully described behavioral performance and predicted the effect of optogenetic inactivation. Thus, sensory signals localized in visual and frontal cortex play a causal role in task performance, while widespread dorsal cortical signals correlating with movement reflect processes that do not play a causal role.},
    urldate = {2025-08-24},
    journal = {eLife},
    author = {Zatka-Haas, Peter and Steinmetz, Nicholas A and Carandini, Matteo and Harris, Kenneth D},
    editor = {Vinck, Martin and Gold, Joshua I and Svoboda, Karel},
    month = jul,
    year = {2021},
    note = {Publisher: eLife Sciences Publications, Ltd},
    keywords = {cortex, decision making, optogenetics, perceptual decisions},
    pages = {e63163},
}
@article{tseng_shared_2022,
    title = {Shared and specialized coding across posterior cortical areas for dynamic navigation decisions},
    volume = {110},
    issn = {0896-6273},
    url = {https://www.cell.com/neuron/abstract/S0896-6273(22)00453-6},
    doi = {10.1016/j.neuron.2022.05.012},
    language = {English},
    number = {15},
    urldate = {2025-08-24},
    journal = {Neuron},
    author = {Tseng, Shih-Yi and Chettih, Selmaan N. and Arlt, Charlotte and Barroso-Luque, Roberto and Harvey, Christopher D.},
    month = aug,
    year = {2022},
    pmid = {35679861},
    note = {Publisher: Elsevier},
    keywords = {calcium imaging, conjunctive coding, cortical organization, decision-making, navigation, parietal cortex, population coding, representational geometry, retrosplenial cortex, virtual reality},
    pages = {2484--2502.e16},
}
@article{hajnal_continuous_2023,
    title = {Continuous multiplexed population representations of task context in the mouse primary visual cortex},
    volume = {14},
    copyright = {2023 The Author(s)},
    issn = {2041-1723},
    url = {https://www.nature.com/articles/s41467-023-42441-w},
    doi = {10.1038/s41467-023-42441-w},
    abstract = {Effective task execution requires the representation of multiple task-related variables that determine how stimuli lead to correct responses. Even the primary visual cortex (V1) represents other task-related variables such as expectations, choice, and context. However, it is unclear how V1 can flexibly accommodate these variables without interfering with visual representations. We trained mice on a context-switching cross-modal decision task, where performance depends on inferring task context. We found that the context signal that emerged in V1 was behaviorally relevant as it strongly covaried with performance, independent from movement. Importantly, this signal was integrated into V1 representation by multiplexing visual and context signals into orthogonal subspaces. In addition, auditory and choice signals were also multiplexed as these signals were orthogonal to the context representation. Thus, multiplexing allows V1 to integrate visual inputs with other sensory modalities and cognitive variables to avoid interference with the visual representation while ensuring the maintenance of task-relevant variables.},
    language = {en},
    number = {1},
    urldate = {2025-08-24},
    journal = {Nature Communications},
    author = {Hajnal, Márton Albert and Tran, Duy and Einstein, Michael and Martelo, Mauricio Vallejo and Safaryan, Karen and Polack, Pierre-Olivier and Golshani, Peyman and Orbán, Gergő},
    month = oct,
    year = {2023},
    note = {Publisher: Nature Publishing Group},
    keywords = {Neural encoding, Sensory processing, Striate cortex},
    pages = {6687},
}
@article{faulkner_context_2025,
    title = {Context flexibly modulates cue representations in visual cortex},
    volume = {16},
    copyright = {2025 The Author(s)},
    issn = {2041-1723},
    url = {https://www.nature.com/articles/s41467-025-61314-y},
    doi = {10.1038/s41467-025-61314-y},
    abstract = {Learned sensory cues result in enhanced responses in sensory cortices and, in turn, enhanced responses draw attention towards cues in our environment that guide future decision making. To respond appropriately, one must recognize the cue but also the context. Here we use two-photon imaging in visual cortex as mice learn a visual discrimination task and subsequently experience a change in external context through introduction of a threat stimulus. Stimuli associated with a reward elicit an enhanced response due to newly recruited neurons responding preferentially to the rewarded cue in addition to neurons increasing their response magnitude. Introduction of threat results in a largely separate set of neurons encoding cues, but the maintenance of the enhanced response to a rewarded cue. When the threat is relieved, representations revert to their initial state. These data suggest that external context changes can result in rapid but flexible shifts in the representation of visual cues.},
    language = {en},
    number = {1},
    urldate = {2025-08-24},
    journal = {Nature Communications},
    author = {Faulkner, Alexa D. and Chiu, Alvin S. and Sarabi, Armin and Karthik, Swathi and Li, Yaoxin S. and Burgess, Christian R.},
    month = jul,
    year = {2025},
    note = {Publisher: Nature Publishing Group},
    keywords = {Cortex, Sensory processing, Striate cortex},
    pages = {5516},
}
@article{goltstein_mouse_2021,
    title = {Mouse visual cortex areas represent perceptual and semantic features of learned visual categories},
    volume = {24},
    issn = {15461726},
    doi = {10.1038/s41593-021-00914-5},
    abstract = {Associative memories are stored in distributed networks extending across multiple brain regions. However, it is unclear to what extent sensory cortical areas are part of these networks. Using a paradigm for visual category learning in mice, we investigated whether perceptual and semantic features of learned category associations are already represented at the first stages of visual information processing in the neocortex. Mice learned categorizing visual stimuli, discriminating between categories and generalizing within categories. Inactivation experiments showed that categorization performance was contingent on neuronal activity in the visual cortex. Long-term calcium imaging in nine areas of the visual cortex identified changes in feature tuning and category tuning that occurred during this learning process, most prominently in the postrhinal area (POR). These results provide evidence for the view that associative memories form a brain-wide distributed network, with learning in early stages shaping perceptual representations and supporting semantic content downstream.},
    number = {10},
    journal = {Nature Neuroscience},
    author = {Goltstein, Pieter M. and Reinert, Sandra and Bonhoeffer, Tobias and Hübener, Mark},
    month = oct,
    year = {2021},
    pmid = {34545249},
    note = {Publisher: Nature Research},
    pages = {1441--1451},
}
@article{yao_whole-brain_2023,
    title = {A whole-brain monosynaptic input connectome to neuron classes in mouse visual cortex},
    volume = {26},
    copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
    issn = {1546-1726},
    url = {https://www.nature.com/articles/s41593-022-01219-x},
    doi = {10.1038/s41593-022-01219-x},
    abstract = {Identification of structural connections between neurons is a prerequisite to understanding brain function. Here we developed a pipeline to systematically map brain-wide monosynaptic input connections to genetically defined neuronal populations using an optimized rabies tracing system. We used mouse visual cortex as the exemplar system and revealed quantitative target-specific, layer-specific and cell-class-specific differences in its presynaptic connectomes. The retrograde connectivity indicates the presence of ventral and dorsal visual streams and further reveals topographically organized and continuously varying subnetworks mediated by different higher visual areas. The visual cortex hierarchy can be derived from intracortical feedforward and feedback pathways mediated by upper-layer and lower-layer input neurons. We also identify a new role for layer 6 neurons in mediating reciprocal interhemispheric connections. This study expands our knowledge of the visual system connectomes and demonstrates that the pipeline can be scaled up to dissect connectivity of different cell populations across the mouse brain.},
    language = {en},
    number = {2},
    urldate = {2025-08-24},
    journal = {Nature Neuroscience},
    author = {Yao, Shenqin and Wang, Quanxin and Hirokawa, Karla E. and Ouellette, Benjamin and Ahmed, Ruweida and Bomben, Jasmin and Brouner, Krissy and Casal, Linzy and Caldejon, Shiella and Cho, Andy and Dotson, Nadezhda I. and Daigle, Tanya L. and Egdorf, Tom and Enstrom, Rachel and Gary, Amanda and Gelfand, Emily and Gorham, Melissa and Griffin, Fiona and Gu, Hong and Hancock, Nicole and Howard, Robert and Kuan, Leonard and Lambert, Sophie and Lee, Eric Kenji and Luviano, Jennifer and Mace, Kyla and Maxwell, Michelle and Mortrud, Marty T. and Naeemi, Maitham and Nayan, Chelsea and Ngo, Nhan-Kiet and Nguyen, Thuyanh and North, Kat and Ransford, Shea and Ruiz, Augustin and Seid, Sam and Swapp, Jackie and Taormina, Michael J. and Wakeman, Wayne and Zhou, Thomas and Nicovich, Philip R. and Williford, Ali and Potekhina, Lydia and McGraw, Medea and Ng, Lydia and Groblewski, Peter A. and Tasic, Bosiljka and Mihalas, Stefan and Harris, Julie A. and Cetin, Ali and Zeng, Hongkui},
    month = feb,
    year = {2023},
    note = {Publisher: Nature Publishing Group},
    keywords = {Molecular neuroscience, Neural circuits},
    pages = {350--364},
}
@article{morimoto_organization_2021,
    title = {Organization of feedback projections to mouse primary visual cortex},
    volume = {24},
    issn = {25890042},
    doi = {10.1016/j.isci.2021.102450},
    abstract = {Top-down, context-dependent modulation of visual processing has been a topic of wide interest, including in mouse primary visual cortex (V1). However, the organization of feedback projections to V1 is relatively unknown. Here, we investigated inputs to mouse V1 by injecting retrograde tracers. We developed a software pipeline that maps labeled cell bodies to corresponding brain areas in the Allen Reference Atlas. We identified more than 24 brain areas that provide inputs to V1 and quantified the relative strength of their projections. We also assessed the organization of the projections, based on either the organization of cell bodies in the source area (topography) or the distribution of projections across V1 (bias). Projections from most higher visual and some nonvisual areas to V1 showed both topography and bias. Such organization of feedback projections to V1 suggests that parts of the visual field are differentially modulated by context, which can be ethologically relevant for a navigating animal.},
    number = {5},
    journal = {iScience},
    author = {Morimoto, Mai M. and Uchishiba, Emi and Saleem, Aman B.},
    month = may,
    year = {2021},
    note = {Publisher: Elsevier Inc.},
    keywords = {Optical Imaging, Sensory Neuroscience, Software, Systems Neuroscience},
}